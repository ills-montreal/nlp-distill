{
  "dataset_revision": "4f58c6b202a23cf9a4da393831edf4f9183cad37",
  "evaluation_time": 12.854084014892578,
  "kg_co2_emissions": null,
  "mteb_version": "1.12.83",
  "scores": {
    "test": [
      {
        "accuracy": 0.5995,
        "f1": 0.5555002008535876,
        "f1_weighted": 0.6175259243990234,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.5995,
        "scores_per_experiment": [
          {
            "accuracy": 0.627,
            "f1": 0.580860283963612,
            "f1_weighted": 0.6415198090011488
          },
          {
            "accuracy": 0.604,
            "f1": 0.5563725103018075,
            "f1_weighted": 0.6156491228524796
          },
          {
            "accuracy": 0.59,
            "f1": 0.5503214192057989,
            "f1_weighted": 0.6135331725181822
          },
          {
            "accuracy": 0.5935,
            "f1": 0.5542358555803163,
            "f1_weighted": 0.619316621985359
          },
          {
            "accuracy": 0.621,
            "f1": 0.5738513974870508,
            "f1_weighted": 0.6358353134547723
          },
          {
            "accuracy": 0.576,
            "f1": 0.5262484236406099,
            "f1_weighted": 0.5918887773889278
          },
          {
            "accuracy": 0.6325,
            "f1": 0.5783168787971965,
            "f1_weighted": 0.6494086018151863
          },
          {
            "accuracy": 0.575,
            "f1": 0.5370323779479178,
            "f1_weighted": 0.5909136349165627
          },
          {
            "accuracy": 0.6135,
            "f1": 0.563196033886033,
            "f1_weighted": 0.6340718275653089
          },
          {
            "accuracy": 0.5625,
            "f1": 0.5345668277255337,
            "f1_weighted": 0.583122362492308
          }
        ]
      }
    ]
  },
  "task_name": "EmotionClassification"
}