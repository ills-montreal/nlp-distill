{
  "dataset_revision": "e8379541af4e31359cca9fbcf4b00f2671dba205",
  "evaluation_time": 15.014922380447388,
  "kg_co2_emissions": null,
  "mteb_version": "1.12.83",
  "scores": {
    "test": [
      {
        "accuracy": 0.7835820895522387,
        "ap": 0.4214058541506714,
        "ap_weighted": 0.4214058541506714,
        "f1": 0.723941983292115,
        "f1_weighted": 0.8019456592573453,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.7835820895522387,
        "scores_per_experiment": [
          {
            "accuracy": 0.7238805970149254,
            "ap": 0.31908666790595036,
            "ap_weighted": 0.31908666790595036,
            "f1": 0.648048293623413,
            "f1_weighted": 0.7475324729923423
          },
          {
            "accuracy": 0.8014925373134328,
            "ap": 0.4450842594798389,
            "ap_weighted": 0.4450842594798389,
            "f1": 0.7433016745453551,
            "f1_weighted": 0.8177276056092287
          },
          {
            "accuracy": 0.753731343283582,
            "ap": 0.3747347168929579,
            "ap_weighted": 0.3747347168929579,
            "f1": 0.690415048265008,
            "f1_weighted": 0.7756726336365533
          },
          {
            "accuracy": 0.764179104477612,
            "ap": 0.3984638273268922,
            "ap_weighted": 0.3984638273268922,
            "f1": 0.7060228383542166,
            "f1_weighted": 0.7856461825768518
          },
          {
            "accuracy": 0.7865671641791044,
            "ap": 0.4317885031682457,
            "ap_weighted": 0.4317885031682457,
            "f1": 0.7307762557077626,
            "f1_weighted": 0.8054080283513937
          },
          {
            "accuracy": 0.8074626865671641,
            "ap": 0.44807064346996117,
            "ap_weighted": 0.44807064346996117,
            "f1": 0.7472592705229392,
            "f1_weighted": 0.8223754593487612
          },
          {
            "accuracy": 0.8388059701492537,
            "ap": 0.4865951858204336,
            "ap_weighted": 0.4865951858204336,
            "f1": 0.7763795490506329,
            "f1_weighted": 0.8483286445541282
          },
          {
            "accuracy": 0.8164179104477612,
            "ap": 0.46703390723180865,
            "ap_weighted": 0.46703390723180865,
            "f1": 0.759014653289314,
            "f1_weighted": 0.8306370658906793
          },
          {
            "accuracy": 0.7850746268656716,
            "ap": 0.4393299734481865,
            "ap_weighted": 0.4393299734481865,
            "f1": 0.7329524695253595,
            "f1_weighted": 0.8047965242376816
          },
          {
            "accuracy": 0.7582089552238805,
            "ap": 0.4038708567624384,
            "ap_weighted": 0.4038708567624384,
            "f1": 0.7052497800371493,
            "f1_weighted": 0.7813319753758338
          }
        ]
      }
    ]
  },
  "task_name": "AmazonCounterfactualClassification"
}