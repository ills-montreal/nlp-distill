{
  "dataset_revision": "4f58c6b202a23cf9a4da393831edf4f9183cad37",
  "evaluation_time": 13.933485507965088,
  "kg_co2_emissions": null,
  "mteb_version": "1.12.83",
  "scores": {
    "test": [
      {
        "accuracy": 0.6018000000000001,
        "f1": 0.5587818148366938,
        "f1_weighted": 0.6189944548767358,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.6018000000000001,
        "scores_per_experiment": [
          {
            "accuracy": 0.6095,
            "f1": 0.5613146946377997,
            "f1_weighted": 0.630830046113135
          },
          {
            "accuracy": 0.606,
            "f1": 0.5586632063940037,
            "f1_weighted": 0.6154494729069152
          },
          {
            "accuracy": 0.609,
            "f1": 0.5676274328548835,
            "f1_weighted": 0.6257962562165591
          },
          {
            "accuracy": 0.596,
            "f1": 0.5596349332028768,
            "f1_weighted": 0.617731499503849
          },
          {
            "accuracy": 0.617,
            "f1": 0.568122242546402,
            "f1_weighted": 0.6350441123136626
          },
          {
            "accuracy": 0.5895,
            "f1": 0.5429643962563852,
            "f1_weighted": 0.6077855350346375
          },
          {
            "accuracy": 0.6095,
            "f1": 0.5554264451306821,
            "f1_weighted": 0.6255977927660566
          },
          {
            "accuracy": 0.5965,
            "f1": 0.5547488195859832,
            "f1_weighted": 0.6097949624760773
          },
          {
            "accuracy": 0.6105,
            "f1": 0.5639877707960068,
            "f1_weighted": 0.6286055705691217
          },
          {
            "accuracy": 0.5745,
            "f1": 0.5553282069619154,
            "f1_weighted": 0.5933093008673425
          }
        ]
      }
    ]
  },
  "task_name": "EmotionClassification"
}