{
  "dataset_revision": "e8379541af4e31359cca9fbcf4b00f2671dba205",
  "evaluation_time": 12.580569505691528,
  "kg_co2_emissions": null,
  "mteb_version": "1.12.83",
  "scores": {
    "test": [
      {
        "accuracy": 0.7919402985074628,
        "ap": 0.4339733272297874,
        "ap_weighted": 0.4339733272297874,
        "f1": 0.7330542103983343,
        "f1_weighted": 0.8092608729237363,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.7919402985074628,
        "scores_per_experiment": [
          {
            "accuracy": 0.7388059701492538,
            "ap": 0.33723001676459574,
            "ap_weighted": 0.33723001676459574,
            "f1": 0.6646886394509186,
            "f1_weighted": 0.7606882296887622
          },
          {
            "accuracy": 0.8044776119402985,
            "ap": 0.45816338156545516,
            "ap_weighted": 0.45816338156545516,
            "f1": 0.7498938537775233,
            "f1_weighted": 0.8210445672932176
          },
          {
            "accuracy": 0.755223880597015,
            "ap": 0.37838842313699644,
            "ap_weighted": 0.37838842313699644,
            "f1": 0.6928117731257828,
            "f1_weighted": 0.7771301169942023
          },
          {
            "accuracy": 0.7835820895522388,
            "ap": 0.41914083659644724,
            "ap_weighted": 0.41914083659644724,
            "f1": 0.7241459598669995,
            "f1_weighted": 0.8021200463994034
          },
          {
            "accuracy": 0.7820895522388059,
            "ap": 0.4313191257610777,
            "ap_weighted": 0.4313191257610777,
            "f1": 0.7283502177197192,
            "f1_weighted": 0.8019262193431668
          },
          {
            "accuracy": 0.826865671641791,
            "ap": 0.4819111480393601,
            "ap_weighted": 0.4819111480393601,
            "f1": 0.7696120280781635,
            "f1_weighted": 0.8395506106349302
          },
          {
            "accuracy": 0.8552238805970149,
            "ap": 0.5169895232373869,
            "ap_weighted": 0.5169895232373869,
            "f1": 0.7950689147387042,
            "f1_weighted": 0.8626811077695328
          },
          {
            "accuracy": 0.8223880597014925,
            "ap": 0.47541257307122636,
            "ap_weighted": 0.47541257307122636,
            "f1": 0.76504321637065,
            "f1_weighted": 0.8357280987844982
          },
          {
            "accuracy": 0.7955223880597015,
            "ap": 0.44700913044673973,
            "ap_weighted": 0.44700913044673973,
            "f1": 0.7411821762803432,
            "f1_weighted": 0.8133997867232688
          },
          {
            "accuracy": 0.755223880597015,
            "ap": 0.39416911367858865,
            "ap_weighted": 0.39416911367858865,
            "f1": 0.6997453245745391,
            "f1_weighted": 0.77833994560638
          }
        ]
      }
    ]
  },
  "task_name": "AmazonCounterfactualClassification"
}