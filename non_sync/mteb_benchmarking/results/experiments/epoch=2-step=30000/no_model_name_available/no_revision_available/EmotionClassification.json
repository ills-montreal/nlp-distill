{
  "dataset_revision": "4f58c6b202a23cf9a4da393831edf4f9183cad37",
  "evaluation_time": 13.2609281539917,
  "kg_co2_emissions": null,
  "mteb_version": "1.12.83",
  "scores": {
    "test": [
      {
        "accuracy": 0.6009,
        "f1": 0.5586603099521128,
        "f1_weighted": 0.6181439670012241,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.6009,
        "scores_per_experiment": [
          {
            "accuracy": 0.61,
            "f1": 0.5633579381699562,
            "f1_weighted": 0.6283028352452495
          },
          {
            "accuracy": 0.607,
            "f1": 0.5587714429351976,
            "f1_weighted": 0.6163605137478929
          },
          {
            "accuracy": 0.6015,
            "f1": 0.5574055645372816,
            "f1_weighted": 0.619662974545817
          },
          {
            "accuracy": 0.5975,
            "f1": 0.5634097457397778,
            "f1_weighted": 0.6204026650868872
          },
          {
            "accuracy": 0.615,
            "f1": 0.5677721846764711,
            "f1_weighted": 0.633045265732232
          },
          {
            "accuracy": 0.586,
            "f1": 0.536406502472344,
            "f1_weighted": 0.6039379149906314
          },
          {
            "accuracy": 0.605,
            "f1": 0.5548434707193491,
            "f1_weighted": 0.6212998345720703
          },
          {
            "accuracy": 0.606,
            "f1": 0.5607505309237645,
            "f1_weighted": 0.620101332311012
          },
          {
            "accuracy": 0.606,
            "f1": 0.5660169021343565,
            "f1_weighted": 0.624051144386789
          },
          {
            "accuracy": 0.575,
            "f1": 0.5578688172126288,
            "f1_weighted": 0.5942751893936598
          }
        ]
      }
    ]
  },
  "task_name": "EmotionClassification"
}