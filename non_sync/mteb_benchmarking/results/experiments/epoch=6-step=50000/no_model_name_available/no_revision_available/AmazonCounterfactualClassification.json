{
  "dataset_revision": "e8379541af4e31359cca9fbcf4b00f2671dba205",
  "evaluation_time": 15.186923027038574,
  "kg_co2_emissions": null,
  "mteb_version": "1.12.83",
  "scores": {
    "test": [
      {
        "accuracy": 0.7876119402985075,
        "ap": 0.4243711584642208,
        "ap_weighted": 0.4243711584642208,
        "f1": 0.7272374814390922,
        "f1_weighted": 0.805258928654308,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.7876119402985075,
        "scores_per_experiment": [
          {
            "accuracy": 0.7432835820895523,
            "ap": 0.33440943692685166,
            "ap_weighted": 0.33440943692685166,
            "f1": 0.6649259720170735,
            "f1_weighted": 0.7635985180342689
          },
          {
            "accuracy": 0.7850746268656716,
            "ap": 0.43007812973463044,
            "ap_weighted": 0.43007812973463044,
            "f1": 0.7293567172720234,
            "f1_weighted": 0.8041360169898144
          },
          {
            "accuracy": 0.7567164179104477,
            "ap": 0.37755487584586367,
            "ap_weighted": 0.37755487584586367,
            "f1": 0.6931225851773797,
            "f1_weighted": 0.7781923679809594
          },
          {
            "accuracy": 0.7791044776119403,
            "ap": 0.4187705293574357,
            "ap_weighted": 0.4187705293574357,
            "f1": 0.7218388483073575,
            "f1_weighted": 0.7986953507950872
          },
          {
            "accuracy": 0.7880597014925373,
            "ap": 0.4381453443960024,
            "ap_weighted": 0.4381453443960024,
            "f1": 0.7340199499015925,
            "f1_weighted": 0.8070272964218095
          },
          {
            "accuracy": 0.817910447761194,
            "ap": 0.46678154572111863,
            "ap_weighted": 0.46678154572111863,
            "f1": 0.7595882352941177,
            "f1_weighted": 0.8316956979806848
          },
          {
            "accuracy": 0.8462686567164179,
            "ap": 0.4945327146363947,
            "ap_weighted": 0.4945327146363947,
            "f1": 0.7823927651349127,
            "f1_weighted": 0.8541871556728029
          },
          {
            "accuracy": 0.8029850746268656,
            "ap": 0.4423183214055764,
            "ap_weighted": 0.4423183214055764,
            "f1": 0.7428501645712424,
            "f1_weighted": 0.8185756068635087
          },
          {
            "accuracy": 0.7880597014925373,
            "ap": 0.43351355791888774,
            "ap_weighted": 0.43351355791888774,
            "f1": 0.7321991533057107,
            "f1_weighted": 0.8066798842214795
          },
          {
            "accuracy": 0.7686567164179104,
            "ap": 0.4076071286994465,
            "ap_weighted": 0.4076071286994465,
            "f1": 0.7120804234095113,
            "f1_weighted": 0.7898013915826658
          }
        ]
      }
    ]
  },
  "task_name": "AmazonCounterfactualClassification"
}