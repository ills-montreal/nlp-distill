{
  "dataset_revision": "4f58c6b202a23cf9a4da393831edf4f9183cad37",
  "evaluation_time": 16.310972452163696,
  "kg_co2_emissions": null,
  "mteb_version": "1.12.83",
  "scores": {
    "test": [
      {
        "accuracy": 0.60535,
        "f1": 0.5618579567634429,
        "f1_weighted": 0.6218498242263198,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.60535,
        "scores_per_experiment": [
          {
            "accuracy": 0.607,
            "f1": 0.5579395135881432,
            "f1_weighted": 0.6277638842569899
          },
          {
            "accuracy": 0.6085,
            "f1": 0.5598807507986782,
            "f1_weighted": 0.6152991018069524
          },
          {
            "accuracy": 0.61,
            "f1": 0.5657756913418938,
            "f1_weighted": 0.6279815392225717
          },
          {
            "accuracy": 0.5975,
            "f1": 0.5589730577184314,
            "f1_weighted": 0.620279000669023
          },
          {
            "accuracy": 0.616,
            "f1": 0.5685304000213192,
            "f1_weighted": 0.6336439458503774
          },
          {
            "accuracy": 0.5935,
            "f1": 0.5482294325205048,
            "f1_weighted": 0.6109262272902413
          },
          {
            "accuracy": 0.62,
            "f1": 0.5653904015518186,
            "f1_weighted": 0.6349547039448926
          },
          {
            "accuracy": 0.6075,
            "f1": 0.5624485236509419,
            "f1_weighted": 0.6220273808294701
          },
          {
            "accuracy": 0.6165,
            "f1": 0.5702939921599504,
            "f1_weighted": 0.6326536984485166
          },
          {
            "accuracy": 0.577,
            "f1": 0.5611178042827486,
            "f1_weighted": 0.5929687599441636
          }
        ]
      }
    ]
  },
  "task_name": "EmotionClassification"
}