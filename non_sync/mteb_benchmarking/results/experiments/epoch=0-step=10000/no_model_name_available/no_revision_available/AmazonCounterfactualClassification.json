{
  "dataset_revision": "e8379541af4e31359cca9fbcf4b00f2671dba205",
  "evaluation_time": 10.600005626678467,
  "kg_co2_emissions": null,
  "mteb_version": "1.12.83",
  "scores": {
    "test": [
      {
        "accuracy": 0.7788059701492537,
        "ap": 0.41319117964546165,
        "ap_weighted": 0.41319117964546165,
        "f1": 0.7183406916139703,
        "f1_weighted": 0.7976517447002264,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.7788059701492537,
        "scores_per_experiment": [
          {
            "accuracy": 0.7253731343283583,
            "ap": 0.31808869140303575,
            "ap_weighted": 0.31808869140303575,
            "f1": 0.6480770987485156,
            "f1_weighted": 0.7485127118586296
          },
          {
            "accuracy": 0.7910447761194029,
            "ap": 0.4370084740370715,
            "ap_weighted": 0.4370084740370715,
            "f1": 0.7350551921273542,
            "f1_weighted": 0.8092232124804577
          },
          {
            "accuracy": 0.7492537313432835,
            "ap": 0.3795359512970734,
            "ap_weighted": 0.3795359512970734,
            "f1": 0.6904596904596905,
            "f1_weighted": 0.7726102681326562
          },
          {
            "accuracy": 0.7865671641791044,
            "ap": 0.420219648757304,
            "ap_weighted": 0.420219648757304,
            "f1": 0.726002716808465,
            "f1_weighted": 0.8044480962599598
          },
          {
            "accuracy": 0.7820895522388059,
            "ap": 0.4197749726632033,
            "ap_weighted": 0.4197749726632033,
            "f1": 0.723700414647098,
            "f1_weighted": 0.8010470644439059
          },
          {
            "accuracy": 0.7880597014925373,
            "ap": 0.42656698349059086,
            "ap_weighted": 0.42656698349059086,
            "f1": 0.729374551991717,
            "f1_weighted": 0.8061166705697129
          },
          {
            "accuracy": 0.8388059701492537,
            "ap": 0.47077216035797975,
            "ap_weighted": 0.47077216035797975,
            "f1": 0.7691689315928492,
            "f1_weighted": 0.846375213470602
          },
          {
            "accuracy": 0.7895522388059701,
            "ap": 0.4329363801635698,
            "ap_weighted": 0.4329363801635698,
            "f1": 0.7326968838687224,
            "f1_weighted": 0.8077680321353796
          },
          {
            "accuracy": 0.7761194029850746,
            "ap": 0.424715804061171,
            "ap_weighted": 0.424715804061171,
            "f1": 0.7227310850180984,
            "f1_weighted": 0.7968209956661471
          },
          {
            "accuracy": 0.7611940298507462,
            "ap": 0.40229273022361745,
            "ap_weighted": 0.40229273022361745,
            "f1": 0.7061403508771928,
            "f1_weighted": 0.7835951819848127
          }
        ]
      }
    ]
  },
  "task_name": "AmazonCounterfactualClassification"
}