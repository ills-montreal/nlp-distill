{
  "dataset_revision": "e8379541af4e31359cca9fbcf4b00f2671dba205",
  "evaluation_time": 12.179786920547485,
  "kg_co2_emissions": null,
  "mteb_version": "1.12.83",
  "scores": {
    "test": [
      {
        "accuracy": 0.6297014925373134,
        "ap": 0.2709732331362582,
        "ap_weighted": 0.2709732331362582,
        "f1": 0.5739730595292137,
        "f1_weighted": 0.6672596390203865,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.6297014925373134,
        "scores_per_experiment": [
          {
            "accuracy": 0.5343283582089552,
            "ap": 0.22578683538009048,
            "ap_weighted": 0.22578683538009048,
            "f1": 0.4945303658996605,
            "f1_weighted": 0.5809004768687682
          },
          {
            "accuracy": 0.6597014925373135,
            "ap": 0.2994686702485281,
            "ap_weighted": 0.2994686702485281,
            "f1": 0.6066779270000824,
            "f1_weighted": 0.6946194503301241
          },
          {
            "accuracy": 0.655223880597015,
            "ap": 0.28942659476156113,
            "ap_weighted": 0.28942659476156113,
            "f1": 0.5989365092938825,
            "f1_weighted": 0.6904315192208865
          },
          {
            "accuracy": 0.6313432835820896,
            "ap": 0.25148501100670384,
            "ap_weighted": 0.25148501100670384,
            "f1": 0.5629761668977356,
            "f1_weighted": 0.6682357276796844
          },
          {
            "accuracy": 0.6880597014925374,
            "ap": 0.31480666380714306,
            "ap_weighted": 0.31480666380714306,
            "f1": 0.6291686418033373,
            "f1_weighted": 0.7191594745868338
          },
          {
            "accuracy": 0.6253731343283582,
            "ap": 0.26051354645781866,
            "ap_weighted": 0.26051354645781866,
            "f1": 0.5664503687891702,
            "f1_weighted": 0.6637802810968169
          },
          {
            "accuracy": 0.6388059701492538,
            "ap": 0.25808462928207715,
            "ap_weighted": 0.25808462928207715,
            "f1": 0.5712215452314462,
            "f1_weighted": 0.6748848736768052
          },
          {
            "accuracy": 0.6537313432835821,
            "ap": 0.2794093229167305,
            "ap_weighted": 0.2794093229167305,
            "f1": 0.5923419879360083,
            "f1_weighted": 0.6886760532506625
          },
          {
            "accuracy": 0.6164179104477612,
            "ap": 0.27693378444650296,
            "ap_weighted": 0.27693378444650296,
            "f1": 0.5714651913461801,
            "f1_weighted": 0.6559845894726551
          },
          {
            "accuracy": 0.5940298507462687,
            "ap": 0.2538172730554263,
            "ap_weighted": 0.2538172730554263,
            "f1": 0.5459618910946344,
            "f1_weighted": 0.6359239440206288
          }
        ]
      }
    ]
  },
  "task_name": "AmazonCounterfactualClassification"
}