{
  "dataset_revision": "4f58c6b202a23cf9a4da393831edf4f9183cad37",
  "evaluation_time": 14.511636734008789,
  "kg_co2_emissions": null,
  "mteb_version": "1.12.83",
  "scores": {
    "test": [
      {
        "accuracy": 0.42745000000000005,
        "f1": 0.3778824040496203,
        "f1_weighted": 0.4552996923938828,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.42745000000000005,
        "scores_per_experiment": [
          {
            "accuracy": 0.462,
            "f1": 0.40314636633161505,
            "f1_weighted": 0.4912050091785564
          },
          {
            "accuracy": 0.403,
            "f1": 0.3645987068715413,
            "f1_weighted": 0.42798471983545916
          },
          {
            "accuracy": 0.439,
            "f1": 0.38103075385253965,
            "f1_weighted": 0.47234595973120513
          },
          {
            "accuracy": 0.4345,
            "f1": 0.37579360041940757,
            "f1_weighted": 0.4631245122861522
          },
          {
            "accuracy": 0.442,
            "f1": 0.39406513644274427,
            "f1_weighted": 0.46521391862723266
          },
          {
            "accuracy": 0.4505,
            "f1": 0.3916434756036477,
            "f1_weighted": 0.4821224935405553
          },
          {
            "accuracy": 0.4125,
            "f1": 0.35962549267672556,
            "f1_weighted": 0.4462644225413513
          },
          {
            "accuracy": 0.392,
            "f1": 0.35393984517859073,
            "f1_weighted": 0.41337295935270674
          },
          {
            "accuracy": 0.43,
            "f1": 0.381727297526878,
            "f1_weighted": 0.4552888113432354
          },
          {
            "accuracy": 0.409,
            "f1": 0.373253365592513,
            "f1_weighted": 0.43607411750237357
          }
        ]
      }
    ]
  },
  "task_name": "EmotionClassification"
}