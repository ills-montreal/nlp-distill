{
  "dataset_revision": "e8379541af4e31359cca9fbcf4b00f2671dba205",
  "evaluation_time": 13.806929588317871,
  "kg_co2_emissions": null,
  "mteb_version": "1.12.83",
  "scores": {
    "test": [
      {
        "accuracy": 0.7416417910447761,
        "ap": 0.36807574418376116,
        "ap_weighted": 0.36807574418376116,
        "f1": 0.6806054169878379,
        "f1_weighted": 0.7654684791470169,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.7416417910447761,
        "scores_per_experiment": [
          {
            "accuracy": 0.6985074626865672,
            "ap": 0.3035090794443888,
            "ap_weighted": 0.3035090794443888,
            "f1": 0.6278146278146278,
            "f1_weighted": 0.7265909176356938
          },
          {
            "accuracy": 0.7671641791044777,
            "ap": 0.3946542392059621,
            "ap_weighted": 0.3946542392059621,
            "f1": 0.7057962529274004,
            "f1_weighted": 0.7876201544968366
          },
          {
            "accuracy": 0.7134328358208956,
            "ap": 0.3536279739401535,
            "ap_weighted": 0.3536279739401535,
            "f1": 0.6607630721194924,
            "f1_weighted": 0.7421617978398427
          },
          {
            "accuracy": 0.6850746268656717,
            "ap": 0.3009753110793565,
            "ap_weighted": 0.3009753110793565,
            "f1": 0.6201477277917946,
            "f1_weighted": 0.715780127871729
          },
          {
            "accuracy": 0.746268656716418,
            "ap": 0.3834976442439799,
            "ap_weighted": 0.3834976442439799,
            "f1": 0.6906942136192307,
            "f1_weighted": 0.7705335544067391
          },
          {
            "accuracy": 0.7820895522388059,
            "ap": 0.39670859911217765,
            "ap_weighted": 0.39670859911217765,
            "f1": 0.7134034150171689,
            "f1_weighted": 0.7988422686343272
          },
          {
            "accuracy": 0.7776119402985074,
            "ap": 0.4056298592157096,
            "ap_weighted": 0.4056298592157096,
            "f1": 0.7155281237622211,
            "f1_weighted": 0.7964552711961024
          },
          {
            "accuracy": 0.7477611940298508,
            "ap": 0.37146476939634676,
            "ap_weighted": 0.37146476939634676,
            "f1": 0.686074784233596,
            "f1_weighted": 0.7708157108223903
          },
          {
            "accuracy": 0.7388059701492538,
            "ap": 0.3812160571189852,
            "ap_weighted": 0.3812160571189852,
            "f1": 0.6858884200656352,
            "f1_weighted": 0.7643988216442401
          },
          {
            "accuracy": 0.7597014925373134,
            "ap": 0.38947390908055146,
            "ap_weighted": 0.38947390908055146,
            "f1": 0.6999435325272115,
            "f1_weighted": 0.7814861669222671
          }
        ]
      }
    ]
  },
  "task_name": "AmazonCounterfactualClassification"
}