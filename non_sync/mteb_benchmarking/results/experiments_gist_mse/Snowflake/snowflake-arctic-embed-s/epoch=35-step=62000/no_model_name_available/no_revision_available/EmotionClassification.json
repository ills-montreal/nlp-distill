{
  "dataset_revision": "4f58c6b202a23cf9a4da393831edf4f9183cad37",
  "evaluation_time": 10.466401815414429,
  "kg_co2_emissions": null,
  "mteb_version": "1.12.83",
  "scores": {
    "test": [
      {
        "accuracy": 0.5570999999999999,
        "f1": 0.5047614654225636,
        "f1_weighted": 0.5805171809377305,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.5570999999999999,
        "scores_per_experiment": [
          {
            "accuracy": 0.553,
            "f1": 0.4898577712545844,
            "f1_weighted": 0.5819280469725342
          },
          {
            "accuracy": 0.543,
            "f1": 0.4864029703840158,
            "f1_weighted": 0.5607163462536451
          },
          {
            "accuracy": 0.5615,
            "f1": 0.5144048855167173,
            "f1_weighted": 0.5880658351586087
          },
          {
            "accuracy": 0.5485,
            "f1": 0.4986665654120956,
            "f1_weighted": 0.5780438048505362
          },
          {
            "accuracy": 0.582,
            "f1": 0.5342193945820578,
            "f1_weighted": 0.6033758087071599
          },
          {
            "accuracy": 0.5445,
            "f1": 0.4865153020706942,
            "f1_weighted": 0.5672771254085253
          },
          {
            "accuracy": 0.5795,
            "f1": 0.5199554211721092,
            "f1_weighted": 0.6040248655908772
          },
          {
            "accuracy": 0.533,
            "f1": 0.4901381320827518,
            "f1_weighted": 0.548667947690108
          },
          {
            "accuracy": 0.5675,
            "f1": 0.5128315408695178,
            "f1_weighted": 0.592026651991343
          },
          {
            "accuracy": 0.5585,
            "f1": 0.5146226708810928,
            "f1_weighted": 0.5810453767539675
          }
        ]
      }
    ]
  },
  "task_name": "EmotionClassification"
}