{
  "dataset_revision": "e8379541af4e31359cca9fbcf4b00f2671dba205",
  "evaluation_time": 9.11823058128357,
  "kg_co2_emissions": null,
  "mteb_version": "1.12.83",
  "scores": {
    "test": [
      {
        "accuracy": 0.7882089552238807,
        "ap": 0.4241203132876582,
        "ap_weighted": 0.4241203132876582,
        "f1": 0.7275776181889204,
        "f1_weighted": 0.8056392045563454,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.7882089552238807,
        "scores_per_experiment": [
          {
            "accuracy": 0.7671641791044777,
            "ap": 0.3628138399419769,
            "ap_weighted": 0.3628138399419769,
            "f1": 0.6901678998292544,
            "f1_weighted": 0.7842232349918026
          },
          {
            "accuracy": 0.817910447761194,
            "ap": 0.47605130501851034,
            "ap_weighted": 0.47605130501851034,
            "f1": 0.7632207081942899,
            "f1_weighted": 0.8325170241672615
          },
          {
            "accuracy": 0.7402985074626866,
            "ap": 0.38254637184726237,
            "ap_weighted": 0.38254637184726237,
            "f1": 0.6872216438973611,
            "f1_weighted": 0.7656830943852335
          },
          {
            "accuracy": 0.7791044776119403,
            "ap": 0.40034794135564983,
            "ap_weighted": 0.40034794135564983,
            "f1": 0.7138239538239537,
            "f1_weighted": 0.7970566216536363
          },
          {
            "accuracy": 0.7895522388059701,
            "ap": 0.4283025526290053,
            "ap_weighted": 0.4283025526290053,
            "f1": 0.7308017815467998,
            "f1_weighted": 0.8073838472392646
          },
          {
            "accuracy": 0.826865671641791,
            "ap": 0.47960752773566834,
            "ap_weighted": 0.47960752773566834,
            "f1": 0.7686932298425019,
            "f1_weighted": 0.8393311948844959
          },
          {
            "accuracy": 0.8253731343283582,
            "ap": 0.4474699578699691,
            "ap_weighted": 0.4474699578699691,
            "f1": 0.7539385835224544,
            "f1_weighted": 0.8346734775080743
          },
          {
            "accuracy": 0.7835820895522388,
            "ap": 0.42838225099113053,
            "ap_weighted": 0.42838225099113053,
            "f1": 0.7279404969601586,
            "f1_weighted": 0.8028638295593954
          },
          {
            "accuracy": 0.7731343283582089,
            "ap": 0.4146064048009296,
            "ap_weighted": 0.4146064048009296,
            "f1": 0.7171865280369678,
            "f1_weighted": 0.7937862009600094
          },
          {
            "accuracy": 0.7791044776119403,
            "ap": 0.42107498068647964,
            "ap_weighted": 0.42107498068647964,
            "f1": 0.7227813562354626,
            "f1_weighted": 0.7988735202142802
          }
        ]
      }
    ]
  },
  "task_name": "AmazonCounterfactualClassification"
}