{
  "dataset_revision": "e8379541af4e31359cca9fbcf4b00f2671dba205",
  "evaluation_time": 10.997365474700928,
  "kg_co2_emissions": null,
  "mteb_version": "1.12.83",
  "scores": {
    "test": [
      {
        "accuracy": 0.7740298507462686,
        "ap": 0.4079388616888431,
        "ap_weighted": 0.4079388616888431,
        "f1": 0.713673962557971,
        "f1_weighted": 0.7934423918292391,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.7740298507462686,
        "scores_per_experiment": [
          {
            "accuracy": 0.746268656716418,
            "ap": 0.33913028502083936,
            "ap_weighted": 0.33913028502083936,
            "f1": 0.6688221816447821,
            "f1_weighted": 0.7663473724757309
          },
          {
            "accuracy": 0.7955223880597015,
            "ap": 0.4400442225809411,
            "ap_weighted": 0.4400442225809411,
            "f1": 0.7384386104390892,
            "f1_weighted": 0.8128481352608458
          },
          {
            "accuracy": 0.7119402985074627,
            "ap": 0.3588837524251408,
            "ap_weighted": 0.3588837524251408,
            "f1": 0.6622445807899155,
            "f1_weighted": 0.7411389497734143
          },
          {
            "accuracy": 0.753731343283582,
            "ap": 0.36128995833265515,
            "ap_weighted": 0.36128995833265515,
            "f1": 0.6838492886251519,
            "f1_weighted": 0.7743631879922614
          },
          {
            "accuracy": 0.7850746268656716,
            "ap": 0.4231413186409696,
            "ap_weighted": 0.4231413186409696,
            "f1": 0.726530612244898,
            "f1_weighted": 0.8035820895522388
          },
          {
            "accuracy": 0.8283582089552238,
            "ap": 0.4864208196400345,
            "ap_weighted": 0.4864208196400345,
            "f1": 0.7720488386472629,
            "f1_weighted": 0.841040499565125
          },
          {
            "accuracy": 0.8164179104477612,
            "ap": 0.4345819855254098,
            "ap_weighted": 0.4345819855254098,
            "f1": 0.7447619047619047,
            "f1_weighted": 0.8271158493248045
          },
          {
            "accuracy": 0.7731343283582089,
            "ap": 0.41919790361171244,
            "ap_weighted": 0.41919790361171244,
            "f1": 0.719034166151673,
            "f1_weighted": 0.7941119422750291
          },
          {
            "accuracy": 0.7626865671641792,
            "ap": 0.406064486726672,
            "ap_weighted": 0.406064486726672,
            "f1": 0.7084397297053198,
            "f1_weighted": 0.7850235002354743
          },
          {
            "accuracy": 0.7671641791044777,
            "ap": 0.41063388438405685,
            "ap_weighted": 0.41063388438405685,
            "f1": 0.7125697125697127,
            "f1_weighted": 0.7888523918374665
          }
        ]
      }
    ]
  },
  "task_name": "AmazonCounterfactualClassification"
}