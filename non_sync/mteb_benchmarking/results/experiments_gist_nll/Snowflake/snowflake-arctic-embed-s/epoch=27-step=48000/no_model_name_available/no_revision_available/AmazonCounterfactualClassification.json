{
  "dataset_revision": "e8379541af4e31359cca9fbcf4b00f2671dba205",
  "evaluation_time": 9.267807960510254,
  "kg_co2_emissions": null,
  "mteb_version": "1.12.83",
  "scores": {
    "test": [
      {
        "accuracy": 0.7664179104477612,
        "ap": 0.4027664121422586,
        "ap_weighted": 0.4027664121422586,
        "f1": 0.7080551244142921,
        "f1_weighted": 0.7873869275590087,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.7664179104477612,
        "scores_per_experiment": [
          {
            "accuracy": 0.7328358208955223,
            "ap": 0.3302336859914438,
            "ap_weighted": 0.3302336859914438,
            "f1": 0.6582519070700508,
            "f1_weighted": 0.7554731110342437
          },
          {
            "accuracy": 0.7925373134328358,
            "ap": 0.438778725027369,
            "ap_weighted": 0.438778725027369,
            "f1": 0.7364884174308681,
            "f1_weighted": 0.8104947267150197
          },
          {
            "accuracy": 0.7044776119402985,
            "ap": 0.3468420576750055,
            "ap_weighted": 0.3468420576750055,
            "f1": 0.653027703381319,
            "f1_weighted": 0.7343903494745889
          },
          {
            "accuracy": 0.7686567164179104,
            "ap": 0.3938985787953693,
            "ap_weighted": 0.3938985787953693,
            "f1": 0.7061561489337019,
            "f1_weighted": 0.7886811700778996
          },
          {
            "accuracy": 0.7716417910447761,
            "ap": 0.4038561352563859,
            "ap_weighted": 0.4038561352563859,
            "f1": 0.7119494204425711,
            "f1_weighted": 0.7918001981661764
          },
          {
            "accuracy": 0.7985074626865671,
            "ap": 0.44833945979224005,
            "ap_weighted": 0.44833945979224005,
            "f1": 0.7431703764278961,
            "f1_weighted": 0.815766939751169
          },
          {
            "accuracy": 0.8134328358208955,
            "ap": 0.46296203224442806,
            "ap_weighted": 0.46296203224442806,
            "f1": 0.7560265093583861,
            "f1_weighted": 0.8280935284251671
          },
          {
            "accuracy": 0.7791044776119403,
            "ap": 0.42107498068647964,
            "ap_weighted": 0.42107498068647964,
            "f1": 0.7227813562354626,
            "f1_weighted": 0.7988735202142802
          },
          {
            "accuracy": 0.7597014925373134,
            "ap": 0.4053492530136479,
            "ap_weighted": 0.4053492530136479,
            "f1": 0.7066158971918135,
            "f1_weighted": 0.7826121178969504
          },
          {
            "accuracy": 0.7432835820895523,
            "ap": 0.37632921294021704,
            "ap_weighted": 0.37632921294021704,
            "f1": 0.6860835076708507,
            "f1_weighted": 0.7676836138345926
          }
        ]
      }
    ]
  },
  "task_name": "AmazonCounterfactualClassification"
}