{
  "dataset_revision": "e8379541af4e31359cca9fbcf4b00f2671dba205",
  "evaluation_time": 9.782883882522583,
  "kg_co2_emissions": null,
  "mteb_version": "1.12.83",
  "scores": {
    "test": [
      {
        "accuracy": 0.7688059701492538,
        "ap": 0.4035047726132183,
        "ap_weighted": 0.4035047726132183,
        "f1": 0.7094849916179473,
        "f1_weighted": 0.7892380902524102,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.7688059701492538,
        "scores_per_experiment": [
          {
            "accuracy": 0.7283582089552239,
            "ap": 0.32033913545952497,
            "ap_weighted": 0.32033913545952497,
            "f1": 0.6506457638578517,
            "f1_weighted": 0.7509833511987625
          },
          {
            "accuracy": 0.7910447761194029,
            "ap": 0.4277354541093185,
            "ap_weighted": 0.4277354541093185,
            "f1": 0.7312659721983474,
            "f1_weighted": 0.8084487316913559
          },
          {
            "accuracy": 0.7059701492537314,
            "ap": 0.3521832028974577,
            "ap_weighted": 0.3521832028974577,
            "f1": 0.656164115923152,
            "f1_weighted": 0.7358537692520788
          },
          {
            "accuracy": 0.7850746268656716,
            "ap": 0.41389527441374174,
            "ap_weighted": 0.41389527441374174,
            "f1": 0.7225800515274199,
            "f1_weighted": 0.8027617708293279
          },
          {
            "accuracy": 0.7731343283582089,
            "ap": 0.39855198232866335,
            "ap_weighted": 0.39855198232866335,
            "f1": 0.7103164218502884,
            "f1_weighted": 0.7924629149760306
          },
          {
            "accuracy": 0.8029850746268656,
            "ap": 0.4492908501601007,
            "ap_weighted": 0.4492908501601007,
            "f1": 0.7456983805668016,
            "f1_weighted": 0.8191982899268839
          },
          {
            "accuracy": 0.808955223880597,
            "ap": 0.4569949527698336,
            "ap_weighted": 0.4569949527698336,
            "f1": 0.7515758249907305,
            "f1_weighted": 0.8242801565033564
          },
          {
            "accuracy": 0.7701492537313432,
            "ap": 0.41374231816459067,
            "ap_weighted": 0.41374231816459067,
            "f1": 0.7153372472852476,
            "f1_weighted": 0.791402888883911
          },
          {
            "accuracy": 0.7597014925373134,
            "ap": 0.4053492530136479,
            "ap_weighted": 0.4053492530136479,
            "f1": 0.7066158971918135,
            "f1_weighted": 0.7826121178969504
          },
          {
            "accuracy": 0.7626865671641792,
            "ap": 0.39696530281530334,
            "ap_weighted": 0.39696530281530334,
            "f1": 0.7046502407878212,
            "f1_weighted": 0.7843769113654443
          }
        ]
      }
    ]
  },
  "task_name": "AmazonCounterfactualClassification"
}