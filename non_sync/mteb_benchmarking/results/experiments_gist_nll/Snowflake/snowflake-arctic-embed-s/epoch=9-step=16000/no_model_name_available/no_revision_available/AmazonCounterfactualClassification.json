{
  "dataset_revision": "e8379541af4e31359cca9fbcf4b00f2671dba205",
  "evaluation_time": 10.492052555084229,
  "kg_co2_emissions": null,
  "mteb_version": "1.12.83",
  "scores": {
    "test": [
      {
        "accuracy": 0.7459701492537314,
        "ap": 0.377359342607854,
        "ap_weighted": 0.377359342607854,
        "f1": 0.6871824624754804,
        "f1_weighted": 0.769574059127922,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.7459701492537314,
        "scores_per_experiment": [
          {
            "accuracy": 0.7044776119402985,
            "ap": 0.31562205093264856,
            "ap_weighted": 0.31562205093264856,
            "f1": 0.6374974040595044,
            "f1_weighted": 0.7323860318906293
          },
          {
            "accuracy": 0.7686567164179104,
            "ap": 0.40303495671938594,
            "ap_weighted": 0.40303495671938594,
            "f1": 0.7101582756301301,
            "f1_weighted": 0.7894518432095797
          },
          {
            "accuracy": 0.6970149253731344,
            "ap": 0.3414046247702394,
            "ap_weighted": 0.3414046247702394,
            "f1": 0.6466272269291825,
            "f1_weighted": 0.7278848592024327
          },
          {
            "accuracy": 0.7492537313432835,
            "ap": 0.35944904631149394,
            "ap_weighted": 0.35944904631149394,
            "f1": 0.680952380952381,
            "f1_weighted": 0.7708457711442787
          },
          {
            "accuracy": 0.7716417910447761,
            "ap": 0.4015659069747341,
            "ap_weighted": 0.4015659069747341,
            "f1": 0.7109552771597993,
            "f1_weighted": 0.7916070610851105
          },
          {
            "accuracy": 0.7671641791044777,
            "ap": 0.40378133720867015,
            "ap_weighted": 0.40378133720867015,
            "f1": 0.709744068248467,
            "f1_weighted": 0.7883595220379044
          },
          {
            "accuracy": 0.7686567164179104,
            "ap": 0.40074984116807605,
            "ap_weighted": 0.40074984116807605,
            "f1": 0.7091777726125834,
            "f1_weighted": 0.7892682315979743
          },
          {
            "accuracy": 0.7776119402985074,
            "ap": 0.41943745254738557,
            "ap_weighted": 0.41943745254738557,
            "f1": 0.7213779552831574,
            "f1_weighted": 0.7976020944401768
          },
          {
            "accuracy": 0.7119402985074627,
            "ap": 0.3588837524251408,
            "ap_weighted": 0.3588837524251408,
            "f1": 0.6622445807899155,
            "f1_weighted": 0.7411389497734143
          },
          {
            "accuracy": 0.7432835820895523,
            "ap": 0.36966445702076506,
            "ap_weighted": 0.36966445702076506,
            "f1": 0.6830896830896831,
            "f1_weighted": 0.7671962268977195
          }
        ]
      }
    ]
  },
  "task_name": "AmazonCounterfactualClassification"
}