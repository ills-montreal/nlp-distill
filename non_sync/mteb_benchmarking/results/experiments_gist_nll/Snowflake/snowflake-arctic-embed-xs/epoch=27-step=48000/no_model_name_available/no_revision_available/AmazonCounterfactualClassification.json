{
  "dataset_revision": "e8379541af4e31359cca9fbcf4b00f2671dba205",
  "evaluation_time": 6.842988967895508,
  "kg_co2_emissions": null,
  "mteb_version": "1.12.83",
  "scores": {
    "test": [
      {
        "accuracy": 0.7525373134328357,
        "ap": 0.3841311119686973,
        "ap_weighted": 0.3841311119686973,
        "f1": 0.6932232992990304,
        "f1_weighted": 0.7751395193526056,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.7525373134328357,
        "scores_per_experiment": [
          {
            "accuracy": 0.7059701492537314,
            "ap": 0.3207765643741382,
            "ap_weighted": 0.3207765643741382,
            "f1": 0.6410144828992997,
            "f1_weighted": 0.7340036473645914
          },
          {
            "accuracy": 0.7850746268656716,
            "ap": 0.427765653598143,
            "ap_weighted": 0.427765653598143,
            "f1": 0.7284273103945235,
            "f1_weighted": 0.8039570656893877
          },
          {
            "accuracy": 0.7104477611940299,
            "ap": 0.3555926055522826,
            "ap_weighted": 0.3555926055522826,
            "f1": 0.660037244727151,
            "f1_weighted": 0.7397562010003548
          },
          {
            "accuracy": 0.7402985074626866,
            "ap": 0.342837532417276,
            "ap_weighted": 0.342837532417276,
            "f1": 0.668388535539146,
            "f1_weighted": 0.7624246526699299
          },
          {
            "accuracy": 0.744776119402985,
            "ap": 0.386598715173399,
            "ap_weighted": 0.386598715173399,
            "f1": 0.6912350866034782,
            "f1_weighted": 0.7695316506973808
          },
          {
            "accuracy": 0.7701492537313432,
            "ap": 0.39772225419941043,
            "ap_weighted": 0.39772225419941043,
            "f1": 0.7085607113400898,
            "f1_weighted": 0.7901455337285036
          },
          {
            "accuracy": 0.7985074626865671,
            "ap": 0.42278693982839083,
            "ap_weighted": 0.42278693982839083,
            "f1": 0.7324051584120044,
            "f1_weighted": 0.8133953690547121
          },
          {
            "accuracy": 0.7910447761194029,
            "ap": 0.4300535490486499,
            "ap_weighted": 0.4300535490486499,
            "f1": 0.7322325751347402,
            "f1_weighted": 0.8086509764141748
          },
          {
            "accuracy": 0.7402985074626866,
            "ap": 0.39144732942145416,
            "ap_weighted": 0.39144732942145416,
            "f1": 0.6908315565031983,
            "f1_weighted": 0.7661394519937625
          },
          {
            "accuracy": 0.7388059701492538,
            "ap": 0.3657299760738293,
            "ap_weighted": 0.3657299760738293,
            "f1": 0.6791003314366726,
            "f1_weighted": 0.7633906449132577
          }
        ]
      }
    ]
  },
  "task_name": "AmazonCounterfactualClassification"
}