{
  "dataset_revision": "e8379541af4e31359cca9fbcf4b00f2671dba205",
  "evaluation_time": 9.298585414886475,
  "kg_co2_emissions": null,
  "mteb_version": "1.12.83",
  "scores": {
    "test": [
      {
        "accuracy": 0.7204477611940299,
        "ap": 0.34431975791280656,
        "ap_weighted": 0.34431975791280656,
        "f1": 0.6592236594547846,
        "f1_weighted": 0.7467695365521513,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.7204477611940299,
        "scores_per_experiment": [
          {
            "accuracy": 0.664179104477612,
            "ap": 0.29822183057912804,
            "ap_weighted": 0.29822183057912804,
            "f1": 0.6083306702417047,
            "f1_weighted": 0.6983945483770806
          },
          {
            "accuracy": 0.7626865671641792,
            "ap": 0.3810751385699066,
            "ap_weighted": 0.3810751385699066,
            "f1": 0.6975117766817442,
            "f1_weighted": 0.7830143957069322
          },
          {
            "accuracy": 0.6985074626865672,
            "ap": 0.34665816168635155,
            "ap_weighted": 0.34665816168635155,
            "f1": 0.6497412008281573,
            "f1_weighted": 0.729327740181082
          },
          {
            "accuracy": 0.7223880597014926,
            "ap": 0.32219578971766333,
            "ap_weighted": 0.32219578971766333,
            "f1": 0.6492186092595928,
            "f1_weighted": 0.7467778765154591
          },
          {
            "accuracy": 0.7179104477611941,
            "ap": 0.3549837749336439,
            "ap_weighted": 0.3549837749336439,
            "f1": 0.663700174483918,
            "f1_weighted": 0.7459224477074445
          },
          {
            "accuracy": 0.744776119402985,
            "ap": 0.35547650010018345,
            "ap_weighted": 0.35547650010018345,
            "f1": 0.6769500156491874,
            "f1_weighted": 0.7670902447421822
          },
          {
            "accuracy": 0.7477611940298508,
            "ap": 0.34924808595766776,
            "ap_weighted": 0.34924808595766776,
            "f1": 0.6750102608700643,
            "f1_weighted": 0.7686455313091585
          },
          {
            "accuracy": 0.753731343283582,
            "ap": 0.36800580568779073,
            "ap_weighted": 0.36800580568779073,
            "f1": 0.687198481122973,
            "f1_weighted": 0.7750476971796996
          },
          {
            "accuracy": 0.6940298507462687,
            "ap": 0.34759883787171014,
            "ap_weighted": 0.34759883787171014,
            "f1": 0.6476859107710382,
            "f1_weighted": 0.7254979581368574
          },
          {
            "accuracy": 0.6985074626865672,
            "ap": 0.3197336540240197,
            "ap_weighted": 0.3197336540240197,
            "f1": 0.6368894946394652,
            "f1_weighted": 0.7279769256656161
          }
        ]
      }
    ]
  },
  "task_name": "AmazonCounterfactualClassification"
}