{
  "dataset_revision": "e8379541af4e31359cca9fbcf4b00f2671dba205",
  "evaluation_time": 8.512231349945068,
  "kg_co2_emissions": null,
  "mteb_version": "1.12.83",
  "scores": {
    "test": [
      {
        "accuracy": 0.7650746268656717,
        "ap": 0.399869258303835,
        "ap_weighted": 0.399869258303835,
        "f1": 0.7063952042890395,
        "f1_weighted": 0.7861540800441682,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.7650746268656717,
        "scores_per_experiment": [
          {
            "accuracy": 0.7328358208955223,
            "ap": 0.3431982750944744,
            "ap_weighted": 0.3431982750944744,
            "f1": 0.6652795570180213,
            "f1_weighted": 0.7568508382871922
          },
          {
            "accuracy": 0.808955223880597,
            "ap": 0.45467143247017183,
            "ap_weighted": 0.45467143247017183,
            "f1": 0.7506425838266594,
            "f1_weighted": 0.8240733157464326
          },
          {
            "accuracy": 0.7134328358208956,
            "ap": 0.35790627425949956,
            "ap_weighted": 0.35790627425949956,
            "f1": 0.6626278520849724,
            "f1_weighted": 0.7423525957936518
          },
          {
            "accuracy": 0.7507462686567165,
            "ap": 0.3674910824620293,
            "ap_weighted": 0.3674910824620293,
            "f1": 0.685591851071303,
            "f1_weighted": 0.7727492359068723
          },
          {
            "accuracy": 0.7701492537313432,
            "ap": 0.41603320972785424,
            "ap_weighted": 0.41603320972785424,
            "f1": 0.7162547162547164,
            "f1_weighted": 0.791559412454935
          },
          {
            "accuracy": 0.7835820895522388,
            "ap": 0.41221240609414245,
            "ap_weighted": 0.41221240609414245,
            "f1": 0.721162649858931,
            "f1_weighted": 0.8015006037859644
          },
          {
            "accuracy": 0.7850746268656716,
            "ap": 0.4115843453442814,
            "ap_weighted": 0.4115843453442814,
            "f1": 0.7215584415584415,
            "f1_weighted": 0.8025415778251598
          },
          {
            "accuracy": 0.7925373134328358,
            "ap": 0.43645912662481084,
            "ap_weighted": 0.43645912662481084,
            "f1": 0.7355606098035374,
            "f1_weighted": 0.8103081824104627
          },
          {
            "accuracy": 0.7417910447761195,
            "ap": 0.38611375806601966,
            "ap_weighted": 0.38611375806601966,
            "f1": 0.6894782666934565,
            "f1_weighted": 0.7670914065397345
          },
          {
            "accuracy": 0.7716417910447761,
            "ap": 0.4130226728950666,
            "ap_weighted": 0.4130226728950666,
            "f1": 0.7157955147203563,
            "f1_weighted": 0.7925136316912765
          }
        ]
      }
    ]
  },
  "task_name": "AmazonCounterfactualClassification"
}