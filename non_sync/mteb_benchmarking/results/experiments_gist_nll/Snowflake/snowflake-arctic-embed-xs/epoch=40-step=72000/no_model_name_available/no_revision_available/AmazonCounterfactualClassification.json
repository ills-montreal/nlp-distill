{
  "dataset_revision": "e8379541af4e31359cca9fbcf4b00f2671dba205",
  "evaluation_time": 9.005313873291016,
  "kg_co2_emissions": null,
  "mteb_version": "1.12.83",
  "scores": {
    "test": [
      {
        "accuracy": 0.7573134328358208,
        "ap": 0.39095201105396293,
        "ap_weighted": 0.39095201105396293,
        "f1": 0.698523909717952,
        "f1_weighted": 0.7793607317495324,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.7573134328358208,
        "scores_per_experiment": [
          {
            "accuracy": 0.7119402985074627,
            "ap": 0.32921181793144033,
            "ap_weighted": 0.32921181793144033,
            "f1": 0.6483035289318011,
            "f1_weighted": 0.7394045885348534
          },
          {
            "accuracy": 0.7895522388059701,
            "ap": 0.4329363801635698,
            "ap_weighted": 0.4329363801635698,
            "f1": 0.7326968838687224,
            "f1_weighted": 0.8077680321353796
          },
          {
            "accuracy": 0.7014925373134329,
            "ap": 0.34884507695318656,
            "ap_weighted": 0.34884507695318656,
            "f1": 0.6523056803910783,
            "f1_weighted": 0.7319415439796523
          },
          {
            "accuracy": 0.735820895522388,
            "ap": 0.34129788671802874,
            "ap_weighted": 0.34129788671802874,
            "f1": 0.6656149284789836,
            "f1_weighted": 0.7589179726278729
          },
          {
            "accuracy": 0.7567164179104477,
            "ap": 0.4046690919625201,
            "ap_weighted": 0.4046690919625201,
            "f1": 0.7047891679439043,
            "f1_weighted": 0.7801853173615192
          },
          {
            "accuracy": 0.7791044776119403,
            "ap": 0.4095562139532689,
            "ap_weighted": 0.4095562139532689,
            "f1": 0.7179396739068598,
            "f1_weighted": 0.7979244172135036
          },
          {
            "accuracy": 0.7910447761194029,
            "ap": 0.41382933744864187,
            "ap_weighted": 0.41382933744864187,
            "f1": 0.7251813568657783,
            "f1_weighted": 0.8071090247178481
          },
          {
            "accuracy": 0.8014925373134328,
            "ap": 0.4404363888783394,
            "ap_weighted": 0.4404363888783394,
            "f1": 0.741388567232878,
            "f1_weighted": 0.8173093715451578
          },
          {
            "accuracy": 0.7567164179104477,
            "ap": 0.40920196523356067,
            "ap_weighted": 0.40920196523356067,
            "f1": 0.7065596190998225,
            "f1_weighted": 0.7804367812468809
          },
          {
            "accuracy": 0.7492537313432835,
            "ap": 0.3795359512970734,
            "ap_weighted": 0.3795359512970734,
            "f1": 0.6904596904596905,
            "f1_weighted": 0.7726102681326562
          }
        ]
      }
    ]
  },
  "task_name": "AmazonCounterfactualClassification"
}