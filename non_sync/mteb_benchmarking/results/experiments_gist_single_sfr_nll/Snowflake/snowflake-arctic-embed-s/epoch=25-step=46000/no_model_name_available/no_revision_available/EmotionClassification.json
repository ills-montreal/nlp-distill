{
  "dataset_revision": "4f58c6b202a23cf9a4da393831edf4f9183cad37",
  "evaluation_time": 10.524400472640991,
  "kg_co2_emissions": null,
  "mteb_version": "1.12.83",
  "scores": {
    "test": [
      {
        "accuracy": 0.5873999999999999,
        "f1": 0.5376996745635881,
        "f1_weighted": 0.6078961700442522,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.5873999999999999,
        "scores_per_experiment": [
          {
            "accuracy": 0.586,
            "f1": 0.5323721027687972,
            "f1_weighted": 0.6123289432207933
          },
          {
            "accuracy": 0.5765,
            "f1": 0.5279308722796755,
            "f1_weighted": 0.5923523544193444
          },
          {
            "accuracy": 0.593,
            "f1": 0.5436794345427204,
            "f1_weighted": 0.6126626500331457
          },
          {
            "accuracy": 0.5635,
            "f1": 0.5216952460283412,
            "f1_weighted": 0.5927729750445916
          },
          {
            "accuracy": 0.5925,
            "f1": 0.5418714759621056,
            "f1_weighted": 0.6162778944777952
          },
          {
            "accuracy": 0.608,
            "f1": 0.5513309761571374,
            "f1_weighted": 0.6251152477870063
          },
          {
            "accuracy": 0.6075,
            "f1": 0.5507762556272368,
            "f1_weighted": 0.6261528853467988
          },
          {
            "accuracy": 0.561,
            "f1": 0.5185121444953328,
            "f1_weighted": 0.5747093512408672
          },
          {
            "accuracy": 0.6055,
            "f1": 0.5495629675065058,
            "f1_weighted": 0.6256550048617486
          },
          {
            "accuracy": 0.5805,
            "f1": 0.5392652702680291,
            "f1_weighted": 0.6009343940104312
          }
        ]
      }
    ]
  },
  "task_name": "EmotionClassification"
}