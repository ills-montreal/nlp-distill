{
  "dataset_revision": "4f58c6b202a23cf9a4da393831edf4f9183cad37",
  "evaluation_time": 15.183915615081787,
  "kg_co2_emissions": null,
  "mteb_version": "1.12.83",
  "scores": {
    "test": [
      {
        "accuracy": 0.59735,
        "f1": 0.5562739187856424,
        "f1_weighted": 0.613389494745955,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.59735,
        "scores_per_experiment": [
          {
            "accuracy": 0.604,
            "f1": 0.560385657499683,
            "f1_weighted": 0.6208152598897461
          },
          {
            "accuracy": 0.598,
            "f1": 0.5468852790580901,
            "f1_weighted": 0.6082872956202778
          },
          {
            "accuracy": 0.594,
            "f1": 0.5543721527466275,
            "f1_weighted": 0.6115950841124779
          },
          {
            "accuracy": 0.5865,
            "f1": 0.5480730883983741,
            "f1_weighted": 0.6077672334017746
          },
          {
            "accuracy": 0.604,
            "f1": 0.5570726467916643,
            "f1_weighted": 0.6221337583219126
          },
          {
            "accuracy": 0.587,
            "f1": 0.5409115166078616,
            "f1_weighted": 0.6036872327297644
          },
          {
            "accuracy": 0.623,
            "f1": 0.5789817222210528,
            "f1_weighted": 0.6372400502151253
          },
          {
            "accuracy": 0.5955,
            "f1": 0.5540174847003483,
            "f1_weighted": 0.6084191741085386
          },
          {
            "accuracy": 0.6115,
            "f1": 0.5687791859388448,
            "f1_weighted": 0.6277860120922536
          },
          {
            "accuracy": 0.57,
            "f1": 0.553260453893877,
            "f1_weighted": 0.5861638469676788
          }
        ]
      }
    ]
  },
  "task_name": "EmotionClassification"
}