{
  "dataset_revision": "e8379541af4e31359cca9fbcf4b00f2671dba205",
  "evaluation_time": 9.227858304977417,
  "kg_co2_emissions": null,
  "mteb_version": "1.12.83",
  "scores": {
    "test": [
      {
        "accuracy": 0.8013432835820895,
        "ap": 0.43995402602271294,
        "ap_weighted": 0.43995402602271294,
        "f1": 0.7404293895497795,
        "f1_weighted": 0.8168966348420893,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.8013432835820895,
        "scores_per_experiment": [
          {
            "accuracy": 0.7701492537313432,
            "ap": 0.36578546368671816,
            "ap_weighted": 0.36578546368671816,
            "f1": 0.6929203223771145,
            "f1_weighted": 0.7866983104501066
          },
          {
            "accuracy": 0.8164179104477612,
            "ap": 0.46239647329997113,
            "ap_weighted": 0.46239647329997113,
            "f1": 0.7571455093578987,
            "f1_weighted": 0.8302063542058258
          },
          {
            "accuracy": 0.7776119402985074,
            "ap": 0.4033300305994563,
            "ap_weighted": 0.4033300305994563,
            "f1": 0.714506327303925,
            "f1_weighted": 0.7962431212778603
          },
          {
            "accuracy": 0.7865671641791044,
            "ap": 0.427160414323999,
            "ap_weighted": 0.427160414323999,
            "f1": 0.7289053503065765,
            "f1_weighted": 0.8050413375557396
          },
          {
            "accuracy": 0.8104477611940298,
            "ap": 0.46128852202326137,
            "ap_weighted": 0.46128852202326137,
            "f1": 0.7539748857193249,
            "f1_weighted": 0.8257534937993238
          },
          {
            "accuracy": 0.8194029850746268,
            "ap": 0.46423730025221893,
            "ap_weighted": 0.46423730025221893,
            "f1": 0.7592039800995025,
            "f1_weighted": 0.8325209772035346
          },
          {
            "accuracy": 0.8388059701492537,
            "ap": 0.4798053317361336,
            "ap_weighted": 0.4798053317361336,
            "f1": 0.7733792671468838,
            "f1_weighted": 0.8475295305495698
          },
          {
            "accuracy": 0.8208955223880597,
            "ap": 0.46634772589128215,
            "ap_weighted": 0.46634772589128215,
            "f1": 0.7607171343198296,
            "f1_weighted": 0.8337908912598233
          },
          {
            "accuracy": 0.7985074626865671,
            "ap": 0.45298566394141426,
            "ap_weighted": 0.45298566394141426,
            "f1": 0.7449605386704112,
            "f1_weighted": 0.8161238774280388
          },
          {
            "accuracy": 0.7746268656716417,
            "ap": 0.41620333447267477,
            "ap_weighted": 0.41620333447267477,
            "f1": 0.7185805801963288,
            "f1_weighted": 0.7950584546910703
          }
        ]
      }
    ]
  },
  "task_name": "AmazonCounterfactualClassification"
}