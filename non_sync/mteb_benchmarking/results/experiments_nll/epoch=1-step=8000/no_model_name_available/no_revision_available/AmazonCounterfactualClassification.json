{
  "dataset_revision": "e8379541af4e31359cca9fbcf4b00f2671dba205",
  "evaluation_time": 8.673330783843994,
  "kg_co2_emissions": null,
  "mteb_version": "1.12.83",
  "scores": {
    "test": [
      {
        "accuracy": 0.7729850746268656,
        "ap": 0.4032870043502922,
        "ap_weighted": 0.4032870043502922,
        "f1": 0.7115268417775774,
        "f1_weighted": 0.7924941814601352,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.7729850746268656,
        "scores_per_experiment": [
          {
            "accuracy": 0.7373134328358208,
            "ap": 0.3273393646674987,
            "ap_weighted": 0.3273393646674987,
            "f1": 0.6584167593622543,
            "f1_weighted": 0.7583852151921151
          },
          {
            "accuracy": 0.7805970149253731,
            "ap": 0.4204198229833413,
            "ap_weighted": 0.4204198229833413,
            "f1": 0.723245521601686,
            "f1_weighted": 0.7999648962773067
          },
          {
            "accuracy": 0.7432835820895523,
            "ap": 0.3608021726621929,
            "ap_weighted": 0.3608021726621929,
            "f1": 0.6789077737531346,
            "f1_weighted": 0.7664588730906627
          },
          {
            "accuracy": 0.7582089552238805,
            "ap": 0.3902804796111798,
            "ap_weighted": 0.3902804796111798,
            "f1": 0.6995715282160295,
            "f1_weighted": 0.7803960897673919
          },
          {
            "accuracy": 0.7791044776119403,
            "ap": 0.42107498068647964,
            "ap_weighted": 0.42107498068647964,
            "f1": 0.7227813562354626,
            "f1_weighted": 0.7988735202142802
          },
          {
            "accuracy": 0.7865671641791044,
            "ap": 0.41559344153624656,
            "ap_weighted": 0.41559344153624656,
            "f1": 0.7240010485713215,
            "f1_weighted": 0.804022914301652
          },
          {
            "accuracy": 0.8238805970149253,
            "ap": 0.4567879130941681,
            "ap_weighted": 0.4567879130941681,
            "f1": 0.7577818627450981,
            "f1_weighted": 0.8348341015510682
          },
          {
            "accuracy": 0.7925373134328358,
            "ap": 0.4295008350038543,
            "ap_weighted": 0.4295008350038543,
            "f1": 0.7327007471061476,
            "f1_weighted": 0.8097143719051658
          },
          {
            "accuracy": 0.7731343283582089,
            "ap": 0.416901919579372,
            "ap_weighted": 0.416901919579372,
            "f1": 0.7181164956101017,
            "f1_weighted": 0.7939518866953307
          },
          {
            "accuracy": 0.755223880597015,
            "ap": 0.39416911367858865,
            "ap_weighted": 0.39416911367858865,
            "f1": 0.6997453245745391,
            "f1_weighted": 0.77833994560638
          }
        ]
      }
    ]
  },
  "task_name": "AmazonCounterfactualClassification"
}