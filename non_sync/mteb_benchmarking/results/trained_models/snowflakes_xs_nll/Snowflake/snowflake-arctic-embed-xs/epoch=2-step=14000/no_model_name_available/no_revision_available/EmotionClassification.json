{
  "dataset_revision": "4f58c6b202a23cf9a4da393831edf4f9183cad37",
  "evaluation_time": 9.957173347473145,
  "kg_co2_emissions": null,
  "mteb_version": "1.12.83",
  "scores": {
    "test": [
      {
        "accuracy": 0.5919999999999999,
        "f1": 0.5445180214469919,
        "f1_weighted": 0.6126032119930481,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.5919999999999999,
        "scores_per_experiment": [
          {
            "accuracy": 0.609,
            "f1": 0.5516425255392405,
            "f1_weighted": 0.6314397713490596
          },
          {
            "accuracy": 0.587,
            "f1": 0.533036182890864,
            "f1_weighted": 0.603753865905746
          },
          {
            "accuracy": 0.5955,
            "f1": 0.5461221269707534,
            "f1_weighted": 0.6152597240642358
          },
          {
            "accuracy": 0.589,
            "f1": 0.5436476780558029,
            "f1_weighted": 0.6164692421941835
          },
          {
            "accuracy": 0.607,
            "f1": 0.555925124757901,
            "f1_weighted": 0.6296771009491614
          },
          {
            "accuracy": 0.5695,
            "f1": 0.5222001316359849,
            "f1_weighted": 0.5912116548014271
          },
          {
            "accuracy": 0.6105,
            "f1": 0.5565530270021399,
            "f1_weighted": 0.6299763140749239
          },
          {
            "accuracy": 0.5905,
            "f1": 0.5448519916168618,
            "f1_weighted": 0.6032944440510312
          },
          {
            "accuracy": 0.607,
            "f1": 0.5614238964235984,
            "f1_weighted": 0.6256081298136125
          },
          {
            "accuracy": 0.555,
            "f1": 0.5297775295767719,
            "f1_weighted": 0.5793418727271001
          }
        ]
      }
    ]
  },
  "task_name": "EmotionClassification"
}