{
  "dataset_revision": "e8379541af4e31359cca9fbcf4b00f2671dba205",
  "evaluation_time": 7.891370534896851,
  "kg_co2_emissions": null,
  "mteb_version": "1.12.83",
  "scores": {
    "test": [
      {
        "accuracy": 0.7270149253731343,
        "ap": 0.3601917651834471,
        "ap_weighted": 0.3601917651834471,
        "f1": 0.6698660859006139,
        "f1_weighted": 0.7530972288354809,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.7270149253731343,
        "scores_per_experiment": [
          {
            "accuracy": 0.7074626865671642,
            "ap": 0.33014636390740865,
            "ap_weighted": 0.33014636390740865,
            "f1": 0.6466244725738397,
            "f1_weighted": 0.7359122110964166
          },
          {
            "accuracy": 0.755223880597015,
            "ap": 0.38739911596403404,
            "ap_weighted": 0.38739911596403404,
            "f1": 0.6968526529531208,
            "f1_weighted": 0.7778576219283208
          },
          {
            "accuracy": 0.6701492537313433,
            "ap": 0.32929945201351035,
            "ap_weighted": 0.32929945201351035,
            "f1": 0.6265187572989893,
            "f1_weighted": 0.7042534408989911
          },
          {
            "accuracy": 0.7119402985074627,
            "ap": 0.318774199332458,
            "ap_weighted": 0.318774199332458,
            "f1": 0.6426666666666666,
            "f1_weighted": 0.7384756218905473
          },
          {
            "accuracy": 0.7328358208955223,
            "ap": 0.3672018650143294,
            "ap_weighted": 0.3672018650143294,
            "f1": 0.6767899444562724,
            "f1_weighted": 0.7587495057007668
          },
          {
            "accuracy": 0.7149253731343284,
            "ap": 0.3526479635946893,
            "ap_weighted": 0.3526479635946893,
            "f1": 0.661106270738935,
            "f1_weighted": 0.7433466968712215
          },
          {
            "accuracy": 0.7880597014925373,
            "ap": 0.40573628442760085,
            "ap_weighted": 0.40573628442760085,
            "f1": 0.7201764705882353,
            "f1_weighted": 0.8041048287971905
          },
          {
            "accuracy": 0.7701492537313432,
            "ap": 0.39543616628016953,
            "ap_weighted": 0.39543616628016953,
            "f1": 0.7075396825396827,
            "f1_weighted": 0.7899419568822554
          },
          {
            "accuracy": 0.7208955223880597,
            "ap": 0.3790462446039523,
            "ap_weighted": 0.3790462446039523,
            "f1": 0.6753295551426669,
            "f1_weighted": 0.749396944131194
          },
          {
            "accuracy": 0.6985074626865672,
            "ap": 0.33622999669631815,
            "ap_weighted": 0.33622999669631815,
            "f1": 0.6450563860477314,
            "f1_weighted": 0.7289334601579044
          }
        ]
      }
    ]
  },
  "task_name": "AmazonCounterfactualClassification"
}