{
  "dataset_revision": "e8379541af4e31359cca9fbcf4b00f2671dba205",
  "evaluation_time": 7.080791473388672,
  "kg_co2_emissions": null,
  "mteb_version": "1.12.83",
  "scores": {
    "test": [
      {
        "accuracy": 0.6761194029850746,
        "ap": 0.3053471028483083,
        "ap_weighted": 0.3053471028483083,
        "f1": 0.6172614450170432,
        "f1_weighted": 0.7080258779754629,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.6761194029850746,
        "scores_per_experiment": [
          {
            "accuracy": 0.6432835820895523,
            "ap": 0.28128410758173616,
            "ap_weighted": 0.28128410758173616,
            "f1": 0.5882224365155899,
            "f1_weighted": 0.679916099348964
          },
          {
            "accuracy": 0.7119402985074627,
            "ap": 0.3397391080682638,
            "ap_weighted": 0.3397391080682638,
            "f1": 0.6535798004152433,
            "f1_weighted": 0.7401655575847904
          },
          {
            "accuracy": 0.6343283582089553,
            "ap": 0.29120089474359767,
            "ap_weighted": 0.29120089474359767,
            "f1": 0.5887727314860047,
            "f1_weighted": 0.6721211427100576
          },
          {
            "accuracy": 0.6925373134328359,
            "ap": 0.2996950559389422,
            "ap_weighted": 0.2996950559389422,
            "f1": 0.6228508345265551,
            "f1_weighted": 0.7215733463104528
          },
          {
            "accuracy": 0.6776119402985075,
            "ap": 0.32008909571916916,
            "ap_weighted": 0.32008909571916916,
            "f1": 0.6264287705603568,
            "f1_weighted": 0.7106333401295725
          },
          {
            "accuracy": 0.6835820895522388,
            "ap": 0.2922544886702545,
            "ap_weighted": 0.2922544886702545,
            "f1": 0.6142774899251583,
            "f1_weighted": 0.7138418443189923
          },
          {
            "accuracy": 0.7223880597014926,
            "ap": 0.29921228847261827,
            "ap_weighted": 0.29921228847261827,
            "f1": 0.6348838026931054,
            "f1_weighted": 0.7437305614108551
          },
          {
            "accuracy": 0.6865671641791045,
            "ap": 0.31584637534050775,
            "ap_weighted": 0.31584637534050775,
            "f1": 0.6289596101306949,
            "f1_weighted": 0.717989466387328
          },
          {
            "accuracy": 0.6776119402985075,
            "ap": 0.32811837567250673,
            "ap_weighted": 0.32811837567250673,
            "f1": 0.6301558906210069,
            "f1_weighted": 0.7108311750727577
          },
          {
            "accuracy": 0.6313432835820896,
            "ap": 0.28603123827548693,
            "ap_weighted": 0.28603123827548693,
            "f1": 0.584483083296717,
            "f1_weighted": 0.6694562464808591
          }
        ]
      }
    ]
  },
  "task_name": "AmazonCounterfactualClassification"
}