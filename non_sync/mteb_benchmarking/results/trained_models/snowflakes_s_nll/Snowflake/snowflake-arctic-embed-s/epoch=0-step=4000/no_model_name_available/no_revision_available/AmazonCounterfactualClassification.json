{
  "dataset_revision": "e8379541af4e31359cca9fbcf4b00f2671dba205",
  "evaluation_time": 7.570576190948486,
  "kg_co2_emissions": null,
  "mteb_version": "1.12.83",
  "scores": {
    "test": [
      {
        "accuracy": 0.5538805970149253,
        "ap": 0.2241276406369394,
        "ap_weighted": 0.2241276406369394,
        "f1": 0.5020024463028501,
        "f1_weighted": 0.5985927616653072,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.5538805970149253,
        "scores_per_experiment": [
          {
            "accuracy": 0.5417910447761194,
            "ap": 0.20828098047226792,
            "ap_weighted": 0.20828098047226792,
            "f1": 0.4835477998870127,
            "f1_weighted": 0.589162217285926
          },
          {
            "accuracy": 0.5522388059701493,
            "ap": 0.2063733770576259,
            "ap_weighted": 0.2063733770576259,
            "f1": 0.48632762586250955,
            "f1_weighted": 0.598376632045497
          },
          {
            "accuracy": 0.5059701492537313,
            "ap": 0.2290650704923482,
            "ap_weighted": 0.2290650704923482,
            "f1": 0.47953409888312337,
            "f1_weighted": 0.5509639568381436
          },
          {
            "accuracy": 0.5223880597014925,
            "ap": 0.21254903237357378,
            "ap_weighted": 0.21254903237357378,
            "f1": 0.47768975161029414,
            "f1_weighted": 0.5707352092695234
          },
          {
            "accuracy": 0.5537313432835821,
            "ap": 0.23602359231712908,
            "ap_weighted": 0.23602359231712908,
            "f1": 0.5124307879525403,
            "f1_weighted": 0.5988442575682585
          },
          {
            "accuracy": 0.5597014925373134,
            "ap": 0.22825867384847878,
            "ap_weighted": 0.22825867384847878,
            "f1": 0.5101987207922067,
            "f1_weighted": 0.6050209314588899
          },
          {
            "accuracy": 0.5358208955223881,
            "ap": 0.20359155485052716,
            "ap_weighted": 0.20359155485052716,
            "f1": 0.47562856876822923,
            "f1_weighted": 0.5838156582646911
          },
          {
            "accuracy": 0.6507462686567164,
            "ap": 0.24993820559668317,
            "ap_weighted": 0.24993820559668317,
            "f1": 0.5702302631578947,
            "f1_weighted": 0.6835079536527887
          },
          {
            "accuracy": 0.5507462686567164,
            "ap": 0.24510114820300533,
            "ap_weighted": 0.24510114820300533,
            "f1": 0.516215315010591,
            "f1_weighted": 0.5949227400810889
          },
          {
            "accuracy": 0.5656716417910448,
            "ap": 0.2220947711577547,
            "ap_weighted": 0.2220947711577547,
            "f1": 0.5082215311040991,
            "f1_weighted": 0.6105780601882643
          }
        ]
      }
    ]
  },
  "task_name": "AmazonCounterfactualClassification"
}