{
  "dataset_revision": "e8379541af4e31359cca9fbcf4b00f2671dba205",
  "evaluation_time": 7.800067901611328,
  "kg_co2_emissions": null,
  "mteb_version": "1.12.83",
  "scores": {
    "test": [
      {
        "accuracy": 0.5814925373134329,
        "ap": 0.24466165213625318,
        "ap_weighted": 0.24466165213625318,
        "f1": 0.5322877907592659,
        "f1_weighted": 0.623540361858782,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.5814925373134329,
        "scores_per_experiment": [
          {
            "accuracy": 0.5985074626865672,
            "ap": 0.24309540211585517,
            "ap_weighted": 0.24309540211585517,
            "f1": 0.5410853739582564,
            "f1_weighted": 0.6399385899968674
          },
          {
            "accuracy": 0.5671641791044776,
            "ap": 0.23629401658728794,
            "ap_weighted": 0.23629401658728794,
            "f1": 0.5200098814229248,
            "f1_weighted": 0.6116239454899416
          },
          {
            "accuracy": 0.48507462686567165,
            "ap": 0.2169356713860205,
            "ap_weighted": 0.2169356713860205,
            "f1": 0.45903377323650624,
            "f1_weighted": 0.5313104282072509
          },
          {
            "accuracy": 0.6223880597014926,
            "ap": 0.25097887083237724,
            "ap_weighted": 0.25097887083237724,
            "f1": 0.5584239661348096,
            "f1_weighted": 0.6607665158415024
          },
          {
            "accuracy": 0.5850746268656717,
            "ap": 0.24719614415808838,
            "ap_weighted": 0.24719614415808838,
            "f1": 0.5369477232724416,
            "f1_weighted": 0.6278540967263205
          },
          {
            "accuracy": 0.5940298507462687,
            "ap": 0.23401919114480643,
            "ap_weighted": 0.23401919114480643,
            "f1": 0.531954674803012,
            "f1_weighted": 0.635752509986818
          },
          {
            "accuracy": 0.5880597014925373,
            "ap": 0.24988671841793092,
            "ap_weighted": 0.24988671841793092,
            "f1": 0.5402790346158053,
            "f1_weighted": 0.6305314053829658
          },
          {
            "accuracy": 0.6373134328358209,
            "ap": 0.2676948094630674,
            "ap_weighted": 0.2676948094630674,
            "f1": 0.5769971238610412,
            "f1_weighted": 0.6742661122472472
          },
          {
            "accuracy": 0.5597014925373134,
            "ap": 0.25909838461195517,
            "ap_weighted": 0.25909838461195517,
            "f1": 0.5290223729265904,
            "f1_weighted": 0.6022216758574384
          },
          {
            "accuracy": 0.5776119402985075,
            "ap": 0.24141731264514296,
            "ap_weighted": 0.24141731264514296,
            "f1": 0.5291239833612715,
            "f1_weighted": 0.6211383388514681
          }
        ]
      }
    ]
  },
  "task_name": "AmazonCounterfactualClassification"
}