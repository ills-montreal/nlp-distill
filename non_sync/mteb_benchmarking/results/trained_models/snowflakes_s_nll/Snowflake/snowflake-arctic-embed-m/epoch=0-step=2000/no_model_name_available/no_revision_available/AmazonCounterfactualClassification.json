{
  "dataset_revision": "e8379541af4e31359cca9fbcf4b00f2671dba205",
  "evaluation_time": 9.619070768356323,
  "kg_co2_emissions": null,
  "mteb_version": "1.12.83",
  "scores": {
    "test": [
      {
        "accuracy": 0.6440298507462686,
        "ap": 0.2783924416799592,
        "ap_weighted": 0.2783924416799592,
        "f1": 0.585487936909687,
        "f1_weighted": 0.6791838227120229,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.6440298507462686,
        "scores_per_experiment": [
          {
            "accuracy": 0.6298507462686567,
            "ap": 0.24922443399143868,
            "ap_weighted": 0.24922443399143868,
            "f1": 0.5605906744520606,
            "f1_weighted": 0.6668241680654862
          },
          {
            "accuracy": 0.6417910447761194,
            "ap": 0.26808238290225544,
            "ap_weighted": 0.26808238290225544,
            "f1": 0.5794275192500837,
            "f1_weighted": 0.6780489084540473
          },
          {
            "accuracy": 0.6059701492537314,
            "ap": 0.28068406195732143,
            "ap_weighted": 0.28068406195732143,
            "f1": 0.5674247982391782,
            "f1_weighted": 0.6460573143088665
          },
          {
            "accuracy": 0.6791044776119403,
            "ap": 0.27076315771836823,
            "ap_weighted": 0.27076315771836823,
            "f1": 0.597961479099858,
            "f1_weighted": 0.7079493309036108
          },
          {
            "accuracy": 0.6835820895522388,
            "ap": 0.31192600495095657,
            "ap_weighted": 0.31192600495095657,
            "f1": 0.6254258921319396,
            "f1_weighted": 0.7153036517814929
          },
          {
            "accuracy": 0.691044776119403,
            "ap": 0.28120690343545535,
            "ap_weighted": 0.28120690343545535,
            "f1": 0.6102845100105374,
            "f1_weighted": 0.7183179151660035
          },
          {
            "accuracy": 0.664179104477612,
            "ap": 0.27756835185626344,
            "ap_weighted": 0.27756835185626344,
            "f1": 0.5961422543701025,
            "f1_weighted": 0.6970841992568801
          },
          {
            "accuracy": 0.6238805970149254,
            "ap": 0.2805249524765222,
            "ap_weighted": 0.2805249524765222,
            "f1": 0.5774943946188341,
            "f1_weighted": 0.6627447125359749
          },
          {
            "accuracy": 0.6,
            "ap": 0.29183803071017156,
            "ap_weighted": 0.29183803071017156,
            "f1": 0.5688835534213685,
            "f1_weighted": 0.6394141656662665
          },
          {
            "accuracy": 0.6208955223880597,
            "ap": 0.27210613680083906,
            "ap_weighted": 0.27210613680083906,
            "f1": 0.5712442935029074,
            "f1_weighted": 0.6600938609816008
          }
        ]
      }
    ]
  },
  "task_name": "AmazonCounterfactualClassification"
}