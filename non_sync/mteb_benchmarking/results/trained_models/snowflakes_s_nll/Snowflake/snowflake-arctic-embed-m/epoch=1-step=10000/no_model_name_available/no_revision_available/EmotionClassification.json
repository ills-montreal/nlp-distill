{
  "dataset_revision": "4f58c6b202a23cf9a4da393831edf4f9183cad37",
  "evaluation_time": 10.3421151638031,
  "kg_co2_emissions": null,
  "mteb_version": "1.12.83",
  "scores": {
    "test": [
      {
        "accuracy": 0.5868,
        "f1": 0.541241582429053,
        "f1_weighted": 0.6052127104012253,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.5868,
        "scores_per_experiment": [
          {
            "accuracy": 0.61,
            "f1": 0.5563988297855617,
            "f1_weighted": 0.6309411022662794
          },
          {
            "accuracy": 0.588,
            "f1": 0.5423644330958818,
            "f1_weighted": 0.6002153450593835
          },
          {
            "accuracy": 0.5985,
            "f1": 0.5489130478450109,
            "f1_weighted": 0.6164320531738862
          },
          {
            "accuracy": 0.5705,
            "f1": 0.5301058286684402,
            "f1_weighted": 0.5958985911047133
          },
          {
            "accuracy": 0.574,
            "f1": 0.5287254933658402,
            "f1_weighted": 0.5943073594706881
          },
          {
            "accuracy": 0.5685,
            "f1": 0.5223019639853035,
            "f1_weighted": 0.5883077323301853
          },
          {
            "accuracy": 0.608,
            "f1": 0.5556197664328203,
            "f1_weighted": 0.6240715536591128
          },
          {
            "accuracy": 0.5775,
            "f1": 0.5392399614158399,
            "f1_weighted": 0.5920930997672667
          },
          {
            "accuracy": 0.609,
            "f1": 0.5529533116662169,
            "f1_weighted": 0.6242281497137878
          },
          {
            "accuracy": 0.564,
            "f1": 0.5357931880296142,
            "f1_weighted": 0.5856321174669505
          }
        ]
      }
    ]
  },
  "task_name": "EmotionClassification"
}