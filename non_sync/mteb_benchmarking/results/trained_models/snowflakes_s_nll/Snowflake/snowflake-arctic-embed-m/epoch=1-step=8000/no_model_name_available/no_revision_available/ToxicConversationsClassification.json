{
  "dataset_revision": "edfaf9da55d3dd50d43143d90c1ac476895ae6de",
  "evaluation_time": 13.121070384979248,
  "kg_co2_emissions": null,
  "mteb_version": "1.12.83",
  "scores": {
    "test": [
      {
        "accuracy": 0.676708984375,
        "ap": 0.13333945186718055,
        "ap_weighted": 0.13333945186718055,
        "f1": 0.5238233592855037,
        "f1_weighted": 0.7482348373889669,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.676708984375,
        "scores_per_experiment": [
          {
            "accuracy": 0.71240234375,
            "ap": 0.1358852596891362,
            "ap_weighted": 0.1358852596891362,
            "f1": 0.5429567365527537,
            "f1_weighted": 0.7772183458615368
          },
          {
            "accuracy": 0.69970703125,
            "ap": 0.12369566652265747,
            "ap_weighted": 0.12369566652265747,
            "f1": 0.5281068863079736,
            "f1_weighted": 0.7676523517978954
          },
          {
            "accuracy": 0.72509765625,
            "ap": 0.14435953011565347,
            "ap_weighted": 0.14435953011565347,
            "f1": 0.5546476169508481,
            "f1_weighted": 0.7865780571653215
          },
          {
            "accuracy": 0.79638671875,
            "ap": 0.16270000136870055,
            "ap_weighted": 0.16270000136870055,
            "f1": 0.6000073065212107,
            "f1_weighted": 0.8359363007249967
          },
          {
            "accuracy": 0.5361328125,
            "ap": 0.10936104311062755,
            "ap_weighted": 0.10936104311062755,
            "f1": 0.4390497059162726,
            "f1_weighted": 0.6354948652476646
          },
          {
            "accuracy": 0.57958984375,
            "ap": 0.11786718979644328,
            "ap_weighted": 0.11786718979644328,
            "f1": 0.46708300806661457,
            "f1_weighted": 0.6732060524004683
          },
          {
            "accuracy": 0.75927734375,
            "ap": 0.14512844842863895,
            "ap_weighted": 0.14512844842863895,
            "f1": 0.5708770833731784,
            "f1_weighted": 0.810230103925603
          },
          {
            "accuracy": 0.603515625,
            "ap": 0.124249097574514,
            "ap_weighted": 0.124249097574514,
            "f1": 0.48325254182514227,
            "f1_weighted": 0.6931043185391652
          },
          {
            "accuracy": 0.66259765625,
            "ap": 0.1338381230835956,
            "ap_weighted": 0.1338381230835956,
            "f1": 0.5182674118848896,
            "f1_weighted": 0.7402347100877893
          },
          {
            "accuracy": 0.6923828125,
            "ap": 0.1363101589818383,
            "ap_weighted": 0.1363101589818383,
            "f1": 0.5339852954561544,
            "f1_weighted": 0.762693268139228
          }
        ]
      }
    ]
  },
  "task_name": "ToxicConversationsClassification"
}