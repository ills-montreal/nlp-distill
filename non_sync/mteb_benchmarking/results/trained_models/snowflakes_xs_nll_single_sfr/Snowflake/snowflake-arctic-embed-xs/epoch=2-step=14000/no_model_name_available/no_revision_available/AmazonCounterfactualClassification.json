{
  "dataset_revision": "e8379541af4e31359cca9fbcf4b00f2671dba205",
  "evaluation_time": 7.106019735336304,
  "kg_co2_emissions": null,
  "mteb_version": "1.12.83",
  "scores": {
    "test": [
      {
        "accuracy": 0.6925373134328358,
        "ap": 0.324040632010468,
        "ap_weighted": 0.324040632010468,
        "f1": 0.6354777596651807,
        "f1_weighted": 0.7229176356142355,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.6925373134328358,
        "scores_per_experiment": [
          {
            "accuracy": 0.6373134328358209,
            "ap": 0.2800584861949793,
            "ap_weighted": 0.2800584861949793,
            "f1": 0.58443408145919,
            "f1_weighted": 0.6747051080770369
          },
          {
            "accuracy": 0.7268656716417911,
            "ap": 0.35135182415744803,
            "ap_weighted": 0.35135182415744803,
            "f1": 0.666526144013055,
            "f1_weighted": 0.7529069414605087
          },
          {
            "accuracy": 0.6611940298507463,
            "ap": 0.31774652960266386,
            "ap_weighted": 0.31774652960266386,
            "f1": 0.616378995053713,
            "f1_weighted": 0.6962241225523573
          },
          {
            "accuracy": 0.7134328358208956,
            "ap": 0.3282059638851453,
            "ap_weighted": 0.3282059638851453,
            "f1": 0.6484823312092164,
            "f1_weighted": 0.7404955460757618
          },
          {
            "accuracy": 0.6970149253731344,
            "ap": 0.33724676923971986,
            "ap_weighted": 0.33724676923971986,
            "f1": 0.6447443000018284,
            "f1_weighted": 0.7277264601243686
          },
          {
            "accuracy": 0.6895522388059702,
            "ap": 0.3157810564091741,
            "ap_weighted": 0.3157810564091741,
            "f1": 0.6304193319118692,
            "f1_weighted": 0.7204425633028886
          },
          {
            "accuracy": 0.7194029850746269,
            "ap": 0.3157955636706919,
            "ap_weighted": 0.3157955636706919,
            "f1": 0.6442169722853044,
            "f1_weighted": 0.7438140281880433
          },
          {
            "accuracy": 0.7194029850746269,
            "ap": 0.33902834438374463,
            "ap_weighted": 0.33902834438374463,
            "f1": 0.6568819735006974,
            "f1_weighted": 0.7460727872145548
          },
          {
            "accuracy": 0.6955223880597015,
            "ap": 0.34450130711046956,
            "ap_weighted": 0.34450130711046956,
            "f1": 0.6471827277514481,
            "f1_weighted": 0.7267092656779295
          },
          {
            "accuracy": 0.6656716417910448,
            "ap": 0.31069047545064404,
            "ap_weighted": 0.31069047545064404,
            "f1": 0.6155107394654862,
            "f1_weighted": 0.7000795334689073
          }
        ]
      }
    ]
  },
  "task_name": "AmazonCounterfactualClassification"
}